{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Test image\n",
    "im_frame = Image.open(\"../Exercise3/positives/\" + 'p01.png')\n",
    "np_frame = np.array(im_frame.getdata())\n",
    "\n",
    "# Load images (30, 573, 3) == (num_images, num_pixels, rgb)\n",
    "positives = np.zeros((30, 576, 3))\n",
    "for i in range(30):\n",
    "    im_frame = Image.open(\"../Exercise3/positives/\" + 'p' + ('0' if (i+1) < 10 else '') + str(i + 1) + '.png')\n",
    "    positives[i] = np.array(im_frame.getdata())\n",
    "    \n",
    "negatives = np.zeros((30, 576, 3))\n",
    "for i in range(30):\n",
    "    im_frame = Image.open(\"../Exercise3/negatives/\" + 'n' + ('0' if (i+1) < 10 else '') + str(i + 1) + '.png')\n",
    "    negatives[i] = np.array(im_frame.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RGB_means(images):\n",
    "    return np.array([np.mean(img, axis=0) for i,img in enumerate(images)])\n",
    "\n",
    "RGB_means_pos = get_RGB_means(positives)\n",
    "RGB_means_neg = get_RGB_means(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RGB_stds(images):\n",
    "    return np.array([np.std(img, axis=0) for i,img in enumerate(images)])\n",
    "\n",
    "RGB_stds_pos = get_RGB_stds(positives)\n",
    "RGB_stds_neg = get_RGB_stds(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_five(sample):\n",
    "    red = np.mean(np.sort(sample[:, :, 0], axis=1)[:, :5], axis=1)\n",
    "    green = np.mean(np.sort(sample[:, :, 1], axis=1)[:, :5], axis=1)\n",
    "    blue = np.mean(np.sort(sample[:, :, 2], axis=1)[:, :5], axis=1)\n",
    "    return red, green, blue\n",
    "\n",
    "top_red_pos, top_green_pos, top_blue_pos = get_top_five(positives)\n",
    "top_red_neg, top_green_neg, top_blue_neg = get_top_five(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples_pos = np.column_stack((RGB_stds_pos, RGB_means_pos))\n",
    "#samples_neg = np.column_stack((RGB_stds_neg, RGB_means_neg))\n",
    "\n",
    "samples_pos = np.column_stack((RGB_stds_pos, top_red_pos, top_green_pos, top_blue_pos))\n",
    "samples_neg = np.column_stack((RGB_stds_neg, top_red_neg, top_green_neg, top_blue_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(no_of_tests, set_1, set_2):\n",
    "    \n",
    "    all_samples = np.concatenate((set_1, set_2), axis=0)\n",
    "    \n",
    "    n =  len(set_1)\n",
    "    \n",
    "    test_idxs = np.random.randint(0, n * 2, no_of_tests)\n",
    "    \n",
    "    test_features = all_samples[test_idxs,:]\n",
    "    test_labels = (test_idxs >= 30)\n",
    "    \n",
    "    idxs_1 = test_idxs[test_idxs < n]\n",
    "    idxs_2 = test_idxs[test_idxs >= n] - n\n",
    "    \n",
    "    train_1 = np.delete(set_1, idxs_1, axis=0)\n",
    "    train_2 = np.delete(set_2, idxs_2, axis=0)\n",
    "\n",
    "    train_features = np.concatenate((train_1, train_2), axis=0)\n",
    "    train_labels = np.concatenate((np.array([0. for i in range(len(train_1))]), \n",
    "                                   np.array([1. for j in range(len(train_2))])\n",
    "                                  ))\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(no_of_tests, iterations, kernel='linear'):\n",
    "    train_features, train_labels, test_features, test_labels = split_data(no_of_tests, samples_neg, samples_pos)\n",
    "\n",
    "    clf = svm.SVC(kernel=kernel, max_iter=iterations)\n",
    "    clf.fit(train_features, train_labels) \n",
    "    #print(linear_clf.coef_)\n",
    "    #print(linear_clf.intercept_)\n",
    "    return clf.score(test_features, test_labels)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Accuracies:--\n",
      "Linear:  0.95 \n",
      "Polynomial:  1.0 \n",
      "Sigmoid:  0.25 \n",
      "Radial basis:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:244: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "iterations=10000\n",
    "test_split_size=20\n",
    "print(\"--Accuracies:--\\nLinear: \", train_and_test(test_split_size,iterations,'linear'),\n",
    "      \"\\nPolynomial: \", train_and_test(test_split_size,iterations,'poly'),\n",
    "      \"\\nSigmoid: \", train_and_test(test_split_size,iterations,'sigmoid'),\n",
    "      \"\\nRadial basis: \", train_and_test(test_split_size,iterations,'rbf')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
